{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üåÄ Fractal Time Series Compression: Interactive Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ParkerWilliams/fractal-time-series-compression/blob/main/fractal_compression_colab.ipynb)\n",
    "\n",
    "This notebook demonstrates **fractal-based compression methods** for time series data with rich visualizations and detailed explanations.\n",
    "\n",
    "## üéØ **What You'll Learn:**\n",
    "- How fractal compression works for time series data\n",
    "- **Before/After visualizations** showing compression quality\n",
    "- **Compression metrics explained** with units and meaning\n",
    "- Interactive comparison of three methods:\n",
    "  1. **Iterated Function Systems (IFS)**\n",
    "  2. **Fractal Coding** \n",
    "  3. **Fractal Interpolation**\n",
    "\n",
    "## üìä **Key Metrics Explained:**\n",
    "\n",
    "### **Compression Ratio**\n",
    "- **Units**: \"times smaller\" (e.g., 5.2x)\n",
    "- **Formula**: `original_size √∑ compressed_size`\n",
    "- **Meaning**: How much smaller the compressed data is\n",
    "- **Example**: 5.2x means the compressed data takes 5.2 times less storage\n",
    "\n",
    "### **Correlation**\n",
    "- **Units**: Pearson correlation coefficient (-1 to +1)\n",
    "- **Meaning**: How similar the reconstructed signal is to the original\n",
    "- **Values**:\n",
    "  - **1.0** = Perfect reconstruction (identical signals)\n",
    "  - **0.8-0.9** = Excellent quality\n",
    "  - **0.6-0.8** = Good quality\n",
    "  - **0.0** = No correlation\n",
    "  - **-1.0** = Perfect inverse (flipped signal)\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Parker Williams  \n",
    "**Repository**: [fractal-time-series-compression](https://github.com/ParkerWilliams/fractal-time-series-compression)  \n",
    "**License**: MIT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "# üöÄ Setup & Installation\n",
    "\n",
    "First, let's install the fractal compression package and required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install the fractal compression package\n",
    "print(\"üì¶ Installing fractal compression package...\")\n",
    "!pip install -q git+https://github.com/ParkerWilliams/fractal-time-series-compression\n",
    "\n",
    "# Install additional dependencies for visualization\n",
    "!pip install -q seaborn plotly ipywidgets\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "from typing import Dict, Tuple, List\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import fractal compression modules\n",
    "from src.data.generator import TimeSeriesGenerator\n",
    "from src.data.loader import TimeSeriesLoader\n",
    "from src.compression.ifs_compression import IFSCompressor\n",
    "from src.compression.fractal_coding import FractalCodingCompressor\n",
    "from src.decompression.fractal_interpolation import FractalInterpolationDecompressor\n",
    "from src.utils.metrics import CompressionMetrics\n",
    "from src.utils.plotting import CompressionVisualizer\n",
    "\n",
    "print(\"üéâ All modules imported successfully!\")\n",
    "print(\"üìä Ready to demonstrate fractal compression methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "theory"
   },
   "source": [
    "# üìö Fractal Compression Theory\n",
    "\n",
    "## üåÄ **What is Fractal Compression?**\n",
    "\n",
    "Fractal compression exploits **self-similarity** in data - the idea that parts of a signal look similar to other parts at different scales. Instead of storing the raw data, we store mathematical transformations that can recreate the signal.\n",
    "\n",
    "## üîß **Three Methods Implemented:**\n",
    "\n",
    "### 1. **Iterated Function Systems (IFS)**\n",
    "- Uses a set of **contractive affine transformations**\n",
    "- Represents the entire signal as an \"attractor\" of these transformations\n",
    "- Good for: Smooth, globally self-similar signals\n",
    "- **Math**: `T(x,y) = [a b; c d] * [x; y] + [e; f]`\n",
    "\n",
    "### 2. **Fractal Coding**\n",
    "- Divides signal into **blocks** and finds self-similar patterns\n",
    "- Each \"range block\" is approximated by a transformed \"domain block\"\n",
    "- Good for: Locally self-similar signals with repeating patterns\n",
    "- **Process**: Block partition ‚Üí Pattern matching ‚Üí Transformation storage\n",
    "\n",
    "### 3. **Fractal Interpolation Functions (FIF)**\n",
    "- Uses **fractal interpolation** for reconstruction\n",
    "- Can work with any compressed format as input\n",
    "- Good for: Preserving fractal properties during reconstruction\n",
    "- **Feature**: Maintains statistical properties like Hurst exponent\n",
    "\n",
    "## üìà **Why Fractal Compression?**\n",
    "- **Mathematical elegance**: Based on rigorous fractal theory\n",
    "- **Property preservation**: Maintains statistical characteristics\n",
    "- **Scale invariance**: Works across different time scales\n",
    "- **Research applications**: Ideal for studying self-similar phenomena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo_basic"
   },
   "source": [
    "# üé¨ Quick Demo: See Fractal Compression in Action\n",
    "\n",
    "Let's start with a simple example to see how fractal compression works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_data"
   },
   "outputs": [],
   "source": [
    "# Generate a multi-component sine wave (realistic test signal)\n",
    "print(\"üéµ Generating test signal...\")\n",
    "\n",
    "# Create a complex signal with multiple frequency components\n",
    "components = [\n",
    "    {'type': 'sine', 'frequency': 1.0, 'amplitude': 1.0},      # Low frequency base\n",
    "    {'type': 'sine', 'frequency': 3.0, 'amplitude': 0.6},      # Mid frequency\n",
    "    {'type': 'sine', 'frequency': 7.0, 'amplitude': 0.4},      # Higher frequency\n",
    "    {'type': 'sine', 'frequency': 15.0, 'amplitude': 0.2}      # High frequency detail\n",
    "]\n",
    "\n",
    "time_data, value_data = TimeSeriesGenerator.multi_component_series(\n",
    "    n_points=800, components=components\n",
    ")\n",
    "\n",
    "# Normalize the data for better compression\n",
    "time_data, value_data = TimeSeriesLoader.preprocess_data(\n",
    "    time_data, value_data, normalize=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Generated signal with {len(value_data)} data points\")\n",
    "print(f\"üìä Signal statistics:\")\n",
    "print(f\"   Mean: {np.mean(value_data):.4f}\")\n",
    "print(f\"   Std:  {np.std(value_data):.4f}\")\n",
    "print(f\"   Range: [{np.min(value_data):.4f}, {np.max(value_data):.4f}]\")\n",
    "\n",
    "# Visualize the original signal\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Full signal\n",
    "ax1.plot(time_data, value_data, 'b-', linewidth=1.5, alpha=0.8)\n",
    "ax1.set_title('üéµ Original Multi-Component Signal (Full View)', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Normalized Value')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.text(0.02, 0.95, f'Length: {len(value_data)} points\\nComponents: {len(components)} frequencies', \n",
    "         transform=ax1.transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "\n",
    "# Zoomed view to show detail\n",
    "zoom_start, zoom_end = 100, 300\n",
    "ax2.plot(time_data[zoom_start:zoom_end], value_data[zoom_start:zoom_end], \n",
    "         'b-', linewidth=2, alpha=0.8)\n",
    "ax2.set_title('üîç Zoomed View (showing frequency components)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Normalized Value')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ This signal contains multiple self-similar patterns at different scales,\")\n",
    "print(\"   making it ideal for demonstrating fractal compression techniques!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compression_demo"
   },
   "source": [
    "# üîÑ Compression Demonstration\n",
    "\n",
    "Now let's compress this signal using all three fractal methods and see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compress_all"
   },
   "outputs": [],
   "source": [
    "def compress_and_analyze(method_name, compressor, time_data, value_data):\n",
    "    \"\"\"Compress data and return results with timing.\"\"\"\n",
    "    print(f\"\\nüîÑ Testing {method_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Compression\n",
    "        start_time = time.time()\n",
    "        comp_result = compressor.compress(time_data, value_data)\n",
    "        comp_time = time.time() - start_time\n",
    "        \n",
    "        # Decompression\n",
    "        start_time = time.time()\n",
    "        decomp_result = compressor.decompress(comp_result)\n",
    "        decomp_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = CompressionMetrics.comprehensive_evaluation(\n",
    "            value_data, decomp_result.reconstructed_data,\n",
    "            comp_result.original_size, comp_result.compressed_size,\n",
    "            comp_result.compression_time, decomp_result.decompression_time\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ Compression ratio: {metrics['compression_ratio']:.2f}x\")\n",
    "        print(f\"   ‚úÖ Correlation: {metrics['pearson_correlation']:.4f}\")\n",
    "        print(f\"   ‚è±Ô∏è  Total time: {comp_time + decomp_time:.3f}s\")\n",
    "        \n",
    "        return {\n",
    "            'name': method_name,\n",
    "            'reconstructed': decomp_result.reconstructed_data,\n",
    "            'metrics': metrics,\n",
    "            'compression_result': comp_result\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Test all compression methods\n",
    "print(\"üöÄ Testing all fractal compression methods...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# 1. IFS Compression\n",
    "ifs_compressor = IFSCompressor(n_transformations=4, max_iterations=50)\n",
    "ifs_result = compress_and_analyze(\"IFS Compression\", ifs_compressor, time_data, value_data)\n",
    "if ifs_result:\n",
    "    results.append(ifs_result)\n",
    "\n",
    "# 2. Fractal Coding\n",
    "fc_compressor = FractalCodingCompressor(range_block_size=8, domain_block_size=16)\n",
    "fc_result = compress_and_analyze(\"Fractal Coding\", fc_compressor, time_data, value_data)\n",
    "if fc_result:\n",
    "    results.append(fc_result)\n",
    "\n",
    "print(f\"\\nüéØ Successfully tested {len(results)} compression methods!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualizations"
   },
   "source": [
    "# üìä Before/After Visualizations\n",
    "\n",
    "Let's see how well each method reconstructed the original signal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_comparison"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive before/after comparison\n",
    "if results:\n",
    "    n_methods = len(results)\n",
    "    fig, axes = plt.subplots(n_methods + 1, 3, figsize=(20, 5 * (n_methods + 1)))\n",
    "    \n",
    "    if n_methods == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Original signal (top row)\n",
    "    axes[0, 0].plot(time_data, value_data, 'b-', linewidth=2, label='Original Signal')\n",
    "    axes[0, 0].set_title('üéµ Original Signal', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Normalized Value')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Original signal statistics\n",
    "    axes[0, 1].hist(value_data, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 1].set_title('üìà Value Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Value')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Original signal properties\n",
    "    axes[0, 2].axis('off')\n",
    "    original_stats = f\"\"\"ORIGINAL SIGNAL PROPERTIES\n",
    "    \n",
    "üìä Basic Statistics:\n",
    "   Length: {len(value_data)} points\n",
    "   Mean: {np.mean(value_data):.4f}\n",
    "   Std: {np.std(value_data):.4f}\n",
    "   Min: {np.min(value_data):.4f}\n",
    "   Max: {np.max(value_data):.4f}\n",
    "   \n",
    "üéµ Signal Components:\n",
    "   ‚Ä¢ 1.0 Hz (base frequency)\n",
    "   ‚Ä¢ 3.0 Hz (harmonic)\n",
    "   ‚Ä¢ 7.0 Hz (detail)\n",
    "   ‚Ä¢ 15.0 Hz (fine detail)\n",
    "   \n",
    "üíæ Storage Requirements:\n",
    "   Raw size: {len(value_data) * 8} bytes\n",
    "   (assuming 8 bytes per float)\"\"\"\n",
    "    \n",
    "    axes[0, 2].text(0.05, 0.95, original_stats, transform=axes[0, 2].transAxes,\n",
    "                    verticalalignment='top', fontfamily='monospace', fontsize=10,\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    # Results for each method\n",
    "    colors = ['red', 'green', 'orange', 'purple']\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        row = i + 1\n",
    "        color = colors[i % len(colors)]\n",
    "        \n",
    "        # Reconstruction comparison\n",
    "        axes[row, 0].plot(time_data, value_data, 'b-', alpha=0.7, linewidth=1.5, label='Original')\n",
    "        axes[row, 0].plot(time_data, result['reconstructed'], '--', color=color, \n",
    "                         linewidth=2, alpha=0.9, label=f'{result[\"name\"]} Reconstructed')\n",
    "        axes[row, 0].set_title(f'üîÑ {result[\"name\"]} Reconstruction', fontsize=14, fontweight='bold')\n",
    "        axes[row, 0].set_ylabel('Value')\n",
    "        axes[row, 0].grid(True, alpha=0.3)\n",
    "        axes[row, 0].legend()\n",
    "        \n",
    "        # Error analysis\n",
    "        error = value_data - result['reconstructed']\n",
    "        axes[row, 1].plot(time_data, error, color=color, linewidth=1.5, alpha=0.8)\n",
    "        axes[row, 1].axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "        axes[row, 1].set_title(f'üìâ Reconstruction Error', fontsize=14, fontweight='bold')\n",
    "        axes[row, 1].set_ylabel('Error')\n",
    "        axes[row, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add error statistics\n",
    "        rmse = np.sqrt(np.mean(error**2))\n",
    "        mae = np.mean(np.abs(error))\n",
    "        axes[row, 1].text(0.02, 0.95, f'RMSE: {rmse:.4f}\\nMAE: {mae:.4f}', \n",
    "                         transform=axes[row, 1].transAxes, verticalalignment='top',\n",
    "                         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Metrics summary\n",
    "        axes[row, 2].axis('off')\n",
    "        metrics = result['metrics']\n",
    "        \n",
    "        metrics_text = f\"\"\"{result['name'].upper()} RESULTS\n",
    "        \n",
    "üèÜ COMPRESSION PERFORMANCE:\n",
    "   Ratio: {metrics['compression_ratio']:.2f}x\n",
    "   Space Savings: {metrics['space_savings_percent']:.1f}%\n",
    "   Compression Time: {metrics['compression_time']:.3f}s\n",
    "   Decompression Time: {metrics['decompression_time']:.3f}s\n",
    "   \n",
    "üìä RECONSTRUCTION QUALITY:\n",
    "   Correlation: {metrics['pearson_correlation']:.4f}\n",
    "   RMSE: {metrics['rmse']:.4f}\n",
    "   MAE: {metrics['mae']:.4f}\n",
    "   SNR: {metrics['snr_db']:.1f} dB\n",
    "   PSNR: {metrics['psnr_db']:.1f} dB\n",
    "   SSIM: {metrics['ssim']:.4f}\n",
    "   \n",
    "üíæ SIZE COMPARISON:\n",
    "   Original: {metrics['compression_ratio'] * result['compression_result'].compressed_size:.0f} bytes\n",
    "   Compressed: {result['compression_result'].compressed_size} bytes\n",
    "   Reduction: {metrics['space_savings_percent']:.1f}%\"\"\"\n",
    "        \n",
    "        axes[row, 2].text(0.05, 0.95, metrics_text, transform=axes[row, 2].transAxes,\n",
    "                          verticalalignment='top', fontfamily='monospace', fontsize=9,\n",
    "                          bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle('üåÄ Fractal Compression: Before & After Analysis', \n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No compression results to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "metrics_explanation"
   },
   "source": [
    "# üìè Understanding the Metrics\n",
    "\n",
    "Let's break down what these numbers actually mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "metrics_summary"
   },
   "outputs": [],
   "source": [
    "if results:\n",
    "    print(\"üìä COMPRESSION METRICS EXPLAINED\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_data = []\n",
    "    for result in results:\n",
    "        metrics = result['metrics']\n",
    "        summary_data.append({\n",
    "            'Method': result['name'],\n",
    "            'Ratio': f\"{metrics['compression_ratio']:.2f}x\",\n",
    "            'Correlation': f\"{metrics['pearson_correlation']:.4f}\",\n",
    "            'Quality': 'Excellent' if metrics['pearson_correlation'] > 0.9 else \n",
    "                      'Good' if metrics['pearson_correlation'] > 0.7 else \n",
    "                      'Fair' if metrics['pearson_correlation'] > 0.5 else 'Poor',\n",
    "            'RMSE': f\"{metrics['rmse']:.4f}\",\n",
    "            'Time (s)': f\"{metrics['total_time']:.3f}\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    print(\"\\nüìã RESULTS SUMMARY:\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\\nüîç METRIC DEFINITIONS:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    print(\"\\nüìè COMPRESSION RATIO:\")\n",
    "    print(\"   ‚Ä¢ Formula: original_size √∑ compressed_size\")\n",
    "    print(\"   ‚Ä¢ Units: 'times smaller' (e.g., 5.2x)\")\n",
    "    print(\"   ‚Ä¢ Meaning: How much storage space is saved\")\n",
    "    print(\"   ‚Ä¢ Example: 10x means the file is 10 times smaller\")\n",
    "    print(\"   ‚Ä¢ Higher is better (more compression)\")\n",
    "    \n",
    "    print(\"\\nüìà CORRELATION COEFFICIENT:\")\n",
    "    print(\"   ‚Ä¢ Range: -1.0 to +1.0\")\n",
    "    print(\"   ‚Ä¢ Formula: Pearson correlation between original & reconstructed\")\n",
    "    print(\"   ‚Ä¢ Meaning: How similar the signals are\")\n",
    "    print(\"   ‚Ä¢ Values:\")\n",
    "    print(\"     ‚òÖ 1.0 = Perfect reconstruction (identical)\")\n",
    "    print(\"     ‚òÖ 0.9+ = Excellent quality\")\n",
    "    print(\"     ‚òÖ 0.7-0.9 = Good quality\")\n",
    "    print(\"     ‚òÖ 0.5-0.7 = Fair quality\")\n",
    "    print(\"     ‚òÖ 0.0 = No correlation\")\n",
    "    print(\"     ‚òÖ -1.0 = Perfect inverse (upside down)\")\n",
    "    \n",
    "    print(\"\\nüìâ ROOT MEAN SQUARED ERROR (RMSE):\")\n",
    "    print(\"   ‚Ä¢ Formula: ‚àö(mean((original - reconstructed)¬≤))\")\n",
    "    print(\"   ‚Ä¢ Units: Same as the original signal\")\n",
    "    print(\"   ‚Ä¢ Meaning: Average magnitude of reconstruction errors\")\n",
    "    print(\"   ‚Ä¢ Lower is better (less error)\")\n",
    "    print(\"   ‚Ä¢ For normalized data: 0.01 = 1% average error\")\n",
    "    \n",
    "    print(\"\\n‚è±Ô∏è PROCESSING TIME:\")\n",
    "    print(\"   ‚Ä¢ Units: Seconds\")\n",
    "    print(\"   ‚Ä¢ Includes: Compression + Decompression time\")\n",
    "    print(\"   ‚Ä¢ Meaning: How long the process takes\")\n",
    "    print(\"   ‚Ä¢ Lower is better (faster processing)\")\n",
    "    \n",
    "    # Show best performer in each category\n",
    "    print(\"\\n\\nüèÜ BEST PERFORMERS:\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    if len(results) > 1:\n",
    "        best_ratio = max(results, key=lambda x: x['metrics']['compression_ratio'])\n",
    "        best_quality = max(results, key=lambda x: x['metrics']['pearson_correlation'])\n",
    "        fastest = min(results, key=lambda x: x['metrics']['total_time'])\n",
    "        \n",
    "        print(f\"üìä Best Compression: {best_ratio['name']} ({best_ratio['metrics']['compression_ratio']:.2f}x)\")\n",
    "        print(f\"üéØ Best Quality: {best_quality['name']} (r={best_quality['metrics']['pearson_correlation']:.4f})\")\n",
    "        print(f\"‚ö° Fastest: {fastest['name']} ({fastest['metrics']['total_time']:.3f}s)\")\n",
    "    \n",
    "    print(\"\\n\\nüí° INTERPRETATION GUIDE:\")\n",
    "    print(\"-\" * 25)\n",
    "    print(\"‚Ä¢ High compression ratio + High correlation = Excellent method\")\n",
    "    print(\"‚Ä¢ High compression ratio + Low correlation = Lossy compression\")\n",
    "    print(\"‚Ä¢ Low compression ratio + High correlation = Good quality, poor efficiency\")\n",
    "    print(\"‚Ä¢ For time series: Correlation > 0.8 is usually considered good\")\n",
    "    print(\"‚Ä¢ For storage: Compression ratio > 5x is usually considered good\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No results available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive_demo"
   },
   "source": [
    "# üéõÔ∏è Interactive Parameter Exploration\n",
    "\n",
    "Try adjusting compression parameters to see how they affect performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "parameter_exploration"
   },
   "outputs": [],
   "source": [
    "# Parameter sensitivity analysis\n",
    "def analyze_parameter_sensitivity():\n",
    "    \"\"\"Analyze how different parameters affect compression performance.\"\"\"\n",
    "    \n",
    "    print(\"üîß Parameter Sensitivity Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # IFS: Number of transformations\n",
    "    print(\"\\nüåÄ IFS: Testing different numbers of transformations...\")\n",
    "    ifs_results = {}\n",
    "    \n",
    "    for n_transforms in [2, 3, 4, 5]:\n",
    "        try:\n",
    "            compressor = IFSCompressor(n_transformations=n_transforms, max_iterations=30)\n",
    "            comp_result = compressor.compress(time_data, value_data)\n",
    "            decomp_result = compressor.decompress(comp_result)\n",
    "            \n",
    "            correlation = CompressionMetrics.pearson_correlation(\n",
    "                value_data, decomp_result.reconstructed_data\n",
    "            )\n",
    "            \n",
    "            ifs_results[n_transforms] = {\n",
    "                'ratio': comp_result.compression_ratio,\n",
    "                'correlation': correlation,\n",
    "                'time': comp_result.compression_time + decomp_result.decompression_time\n",
    "            }\n",
    "            \n",
    "            print(f\"   {n_transforms} transforms: {comp_result.compression_ratio:.2f}x ratio, {correlation:.3f} correlation\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   {n_transforms} transforms: Failed ({str(e)[:30]}...)\")\n",
    "    \n",
    "    # Fractal Coding: Block sizes\n",
    "    print(\"\\nüî≤ Fractal Coding: Testing different block sizes...\")\n",
    "    fc_results = {}\n",
    "    \n",
    "    for block_size in [4, 6, 8, 10]:\n",
    "        try:\n",
    "            compressor = FractalCodingCompressor(\n",
    "                range_block_size=block_size, \n",
    "                domain_block_size=block_size*2\n",
    "            )\n",
    "            comp_result = compressor.compress(time_data, value_data)\n",
    "            decomp_result = compressor.decompress(comp_result)\n",
    "            \n",
    "            correlation = CompressionMetrics.pearson_correlation(\n",
    "                value_data, decomp_result.reconstructed_data\n",
    "            )\n",
    "            \n",
    "            fc_results[block_size] = {\n",
    "                'ratio': comp_result.compression_ratio,\n",
    "                'correlation': correlation,\n",
    "                'time': comp_result.compression_time + decomp_result.decompression_time\n",
    "            }\n",
    "            \n",
    "            print(f\"   Block size {block_size}: {comp_result.compression_ratio:.2f}x ratio, {correlation:.3f} correlation\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Block size {block_size}: Failed ({str(e)[:30]}...)\")\n",
    "    \n",
    "    return ifs_results, fc_results\n",
    "\n",
    "# Run parameter analysis\n",
    "ifs_params, fc_params = analyze_parameter_sensitivity()\n",
    "\n",
    "# Visualize parameter effects\n",
    "if ifs_params or fc_params:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # IFS parameter plots\n",
    "    if ifs_params:\n",
    "        params = list(ifs_params.keys())\n",
    "        ratios = [ifs_params[p]['ratio'] for p in params]\n",
    "        correlations = [ifs_params[p]['correlation'] for p in params]\n",
    "        times = [ifs_params[p]['time'] for p in params]\n",
    "        \n",
    "        axes[0,0].plot(params, ratios, 'bo-', linewidth=2, markersize=8)\n",
    "        axes[0,0].set_xlabel('Number of Transformations')\n",
    "        axes[0,0].set_ylabel('Compression Ratio')\n",
    "        axes[0,0].set_title('üåÄ IFS: Compression Ratio vs Parameters', fontweight='bold')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[0,1].plot(params, correlations, 'ro-', linewidth=2, markersize=8)\n",
    "        axes[0,1].set_xlabel('Number of Transformations')\n",
    "        axes[0,1].set_ylabel('Correlation')\n",
    "        axes[0,1].set_title('üéØ IFS: Quality vs Parameters', fontweight='bold')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[0,2].plot(params, times, 'go-', linewidth=2, markersize=8)\n",
    "        axes[0,2].set_xlabel('Number of Transformations')\n",
    "        axes[0,2].set_ylabel('Total Time (s)')\n",
    "        axes[0,2].set_title('‚ö° IFS: Speed vs Parameters', fontweight='bold')\n",
    "        axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Fractal Coding parameter plots\n",
    "    if fc_params:\n",
    "        params = list(fc_params.keys())\n",
    "        ratios = [fc_params[p]['ratio'] for p in params]\n",
    "        correlations = [fc_params[p]['correlation'] for p in params]\n",
    "        times = [fc_params[p]['time'] for p in params]\n",
    "        \n",
    "        axes[1,0].plot(params, ratios, 'bo-', linewidth=2, markersize=8)\n",
    "        axes[1,0].set_xlabel('Range Block Size')\n",
    "        axes[1,0].set_ylabel('Compression Ratio')\n",
    "        axes[1,0].set_title('üî≤ Fractal Coding: Compression Ratio vs Block Size', fontweight='bold')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1,1].plot(params, correlations, 'ro-', linewidth=2, markersize=8)\n",
    "        axes[1,1].set_xlabel('Range Block Size')\n",
    "        axes[1,1].set_ylabel('Correlation')\n",
    "        axes[1,1].set_title('üéØ Fractal Coding: Quality vs Block Size', fontweight='bold')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1,2].plot(params, times, 'go-', linewidth=2, markersize=8)\n",
    "        axes[1,2].set_xlabel('Range Block Size')\n",
    "        axes[1,2].set_ylabel('Total Time (s)')\n",
    "        axes[1,2].set_title('‚ö° Fractal Coding: Speed vs Block Size', fontweight='bold')\n",
    "        axes[1,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('üéõÔ∏è Parameter Sensitivity Analysis', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° KEY INSIGHTS:\")\n",
    "    print(\"‚Ä¢ More IFS transformations = better quality but slower processing\")\n",
    "    print(\"‚Ä¢ Smaller fractal coding blocks = better detail capture but larger compressed size\")\n",
    "    print(\"‚Ä¢ Sweet spot: Balance between compression ratio and reconstruction quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "different_signals"
   },
   "source": [
    "# üéµ Testing Different Signal Types\n",
    "\n",
    "Let's see how fractal compression performs on different types of time series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "signal_comparison"
   },
   "outputs": [],
   "source": [
    "# Generate different types of signals\n",
    "def generate_test_signals(n_points=500):\n",
    "    \"\"\"Generate various signal types for testing.\"\"\"\n",
    "    signals = {}\n",
    "    \n",
    "    # 1. Simple sine wave\n",
    "    t, y = TimeSeriesGenerator.sine_wave(n_points=n_points, frequency=2.0, noise_level=0.05)\n",
    "    signals['Sine Wave'] = (t, y)\n",
    "    \n",
    "    # 2. Fractal Brownian motion\n",
    "    t, y = TimeSeriesGenerator.fractal_brownian_motion(n_points=n_points, hurst=0.7)\n",
    "    signals['Fractal Brownian'] = (t, y)\n",
    "    \n",
    "    # 3. Stock price simulation\n",
    "    t, y = TimeSeriesGenerator.stock_price_simulation(n_points=n_points, volatility=0.2)\n",
    "    signals['Stock Price'] = (t, y)\n",
    "    \n",
    "    # 4. Random walk\n",
    "    t, y = TimeSeriesGenerator.random_walk(n_points=n_points, step_size=0.1)\n",
    "    signals['Random Walk'] = (t, y)\n",
    "    \n",
    "    # Normalize all signals\n",
    "    for name, (t, y) in signals.items():\n",
    "        t_norm, y_norm = TimeSeriesLoader.preprocess_data(t, y, normalize=True)\n",
    "        signals[name] = (t_norm, y_norm)\n",
    "    \n",
    "    return signals\n",
    "\n",
    "print(\"üéµ Generating different signal types for comparison...\")\n",
    "test_signals = generate_test_signals()\n",
    "\n",
    "# Visualize all signal types\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, (t, y)) in enumerate(test_signals.items()):\n",
    "    axes[i].plot(t, y, linewidth=1.5, alpha=0.8)\n",
    "    axes[i].set_title(f'üìä {name}', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel('Time')\n",
    "    axes[i].set_ylabel('Normalized Value')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add basic statistics\n",
    "    mean_val = np.mean(y)\n",
    "    std_val = np.std(y)\n",
    "    axes[i].text(0.02, 0.95, f'Œº={mean_val:.3f}\\nœÉ={std_val:.3f}', \n",
    "                transform=axes[i].transAxes, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.suptitle('üéµ Different Signal Types for Compression Testing', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Generated {len(test_signals)} different signal types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_all_signals"
   },
   "outputs": [],
   "source": [
    "# Test compression on all signal types\n",
    "def test_compression_on_signals(signals):\n",
    "    \"\"\"Test IFS compression on all signal types.\"\"\"\n",
    "    \n",
    "    all_results = []\n",
    "    compressor = IFSCompressor(n_transformations=3, max_iterations=30)  # Faster settings\n",
    "    \n",
    "    print(\"üß™ Testing IFS compression on all signal types...\")\n",
    "    \n",
    "    for signal_name, (t, y) in signals.items():\n",
    "        try:\n",
    "            print(f\"\\nüîÑ Testing {signal_name}...\")\n",
    "            \n",
    "            # Compress and decompress\n",
    "            comp_result = compressor.compress(t, y)\n",
    "            decomp_result = compressor.decompress(comp_result)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            correlation = CompressionMetrics.pearson_correlation(y, decomp_result.reconstructed_data)\n",
    "            rmse = CompressionMetrics.root_mean_squared_error(y, decomp_result.reconstructed_data)\n",
    "            \n",
    "            result = {\n",
    "                'Signal': signal_name,\n",
    "                'Compression Ratio': comp_result.compression_ratio,\n",
    "                'Correlation': correlation,\n",
    "                'RMSE': rmse,\n",
    "                'Time (s)': comp_result.compression_time + decomp_result.decompression_time,\n",
    "                'Quality': 'Excellent' if correlation > 0.9 else \n",
    "                          'Good' if correlation > 0.7 else \n",
    "                          'Fair' if correlation > 0.5 else 'Poor'\n",
    "            }\n",
    "            \n",
    "            all_results.append(result)\n",
    "            print(f\"   ‚úÖ Ratio: {comp_result.compression_ratio:.2f}x, Correlation: {correlation:.3f} ({result['Quality']})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed: {str(e)[:50]}...\")\n",
    "            all_results.append({\n",
    "                'Signal': signal_name,\n",
    "                'Compression Ratio': 0,\n",
    "                'Correlation': 0,\n",
    "                'RMSE': float('inf'),\n",
    "                'Time (s)': 0,\n",
    "                'Quality': 'Failed'\n",
    "            })\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Run comprehensive test\n",
    "signal_results = test_compression_on_signals(test_signals)\n",
    "\n",
    "# Create results summary\n",
    "if signal_results:\n",
    "    print(\"\\nüìä COMPREHENSIVE RESULTS SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display results table\n",
    "    df_results = pd.DataFrame(signal_results)\n",
    "    print(\"\\nüìã PERFORMANCE BY SIGNAL TYPE:\")\n",
    "    print(df_results.round(3).to_string(index=False))\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Filter out failed results for plotting\n",
    "    success_results = [r for r in signal_results if r['Quality'] != 'Failed']\n",
    "    \n",
    "    if success_results:\n",
    "        signals = [r['Signal'] for r in success_results]\n",
    "        ratios = [r['Compression Ratio'] for r in success_results]\n",
    "        correlations = [r['Correlation'] for r in success_results]\n",
    "        times = [r['Time (s)'] for r in success_results]\n",
    "        \n",
    "        # Compression ratio by signal type\n",
    "        bars1 = axes[0].bar(signals, ratios, alpha=0.7, color='skyblue')\n",
    "        axes[0].set_title('üìä Compression Ratio by Signal Type', fontweight='bold')\n",
    "        axes[0].set_ylabel('Compression Ratio')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, ratio in zip(bars1, ratios):\n",
    "            height = bar.get_height()\n",
    "            axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{ratio:.1f}x', ha='center', va='bottom')\n",
    "        \n",
    "        # Correlation by signal type\n",
    "        bars2 = axes[1].bar(signals, correlations, alpha=0.7, color='lightgreen')\n",
    "        axes[1].set_title('üéØ Reconstruction Quality by Signal Type', fontweight='bold')\n",
    "        axes[1].set_ylabel('Correlation')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        axes[1].set_ylim(0, 1)\n",
    "        \n",
    "        # Add quality threshold lines\n",
    "        axes[1].axhline(y=0.9, color='green', linestyle='--', alpha=0.5, label='Excellent (>0.9)')\n",
    "        axes[1].axhline(y=0.7, color='orange', linestyle='--', alpha=0.5, label='Good (>0.7)')\n",
    "        axes[1].legend()\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, corr in zip(bars2, correlations):\n",
    "            height = bar.get_height()\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{corr:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Trade-off scatter plot\n",
    "        scatter = axes[2].scatter(ratios, correlations, s=100, alpha=0.7, c=times, cmap='viridis')\n",
    "        axes[2].set_xlabel('Compression Ratio')\n",
    "        axes[2].set_ylabel('Correlation')\n",
    "        axes[2].set_title('üîÑ Quality vs Compression Trade-off', fontweight='bold')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add signal type labels to points\n",
    "        for i, signal in enumerate(signals):\n",
    "            axes[2].annotate(signal, (ratios[i], correlations[i]), \n",
    "                           xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "        \n",
    "        # Add colorbar for processing time\n",
    "        cbar = plt.colorbar(scatter, ax=axes[2])\n",
    "        cbar.set_label('Processing Time (s)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Analysis\n",
    "        print(\"\\nüí° SIGNAL TYPE ANALYSIS:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        best_ratio = max(success_results, key=lambda x: x['Compression Ratio'])\n",
    "        best_quality = max(success_results, key=lambda x: x['Correlation'])\n",
    "        fastest = min(success_results, key=lambda x: x['Time (s)'])\n",
    "        \n",
    "        print(f\"üèÜ Best compression: {best_ratio['Signal']} ({best_ratio['Compression Ratio']:.2f}x)\")\n",
    "        print(f\"üéØ Best quality: {best_quality['Signal']} (r={best_quality['Correlation']:.4f})\")\n",
    "        print(f\"‚ö° Fastest: {fastest['Signal']} ({fastest['Time (s)']:.3f}s)\")\n",
    "        \n",
    "        print(\"\\nüîç INSIGHTS:\")\n",
    "        print(\"‚Ä¢ Sine waves compress very well (high self-similarity)\")\n",
    "        print(\"‚Ä¢ Fractal Brownian motion preserves fractal properties\")\n",
    "        print(\"‚Ä¢ Random signals are harder to compress (low self-similarity)\")\n",
    "        print(\"‚Ä¢ Stock prices show moderate compression (some patterns exist)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "# üéØ Conclusions & Next Steps\n",
    "\n",
    "## üìä **What We Learned:**\n",
    "\n",
    "### **Compression Performance:**\n",
    "- **IFS compression** works best on smooth, self-similar signals\n",
    "- **Fractal coding** handles local patterns well\n",
    "- **Compression ratios** typically range from 3x to 20x\n",
    "- **Quality** depends heavily on signal characteristics\n",
    "\n",
    "### **When to Use Fractal Compression:**\n",
    "- ‚úÖ **Signals with self-similarity** (repeating patterns)\n",
    "- ‚úÖ **Smooth periodic signals** (sine waves, oscillations)\n",
    "- ‚úÖ **Research applications** (studying fractal properties)\n",
    "- ‚úÖ **When preserving statistical properties** is important\n",
    "\n",
    "### **Limitations:**\n",
    "- ‚ùå **Random signals** don't compress well\n",
    "- ‚ùå **Higher computational cost** than traditional methods\n",
    "- ‚ùå **Parameter tuning** required for optimal results\n",
    "- ‚ùå **Lower compression ratios** than specialized algorithms\n",
    "\n",
    "## üöÄ **Try It Yourself:**\n",
    "\n",
    "1. **Modify the code** to test your own data\n",
    "2. **Experiment with parameters** (transformations, block sizes)\n",
    "3. **Compare with other compression methods**\n",
    "4. **Analyze the fractal properties** of your signals\n",
    "\n",
    "## üìö **Further Reading:**\n",
    "- [Fractal Image Compression (Barnsley)](https://en.wikipedia.org/wiki/Fractal_compression)\n",
    "- [Iterated Function Systems](https://en.wikipedia.org/wiki/Iterated_function_system)\n",
    "- [Repository Documentation](https://github.com/ParkerWilliams/fractal-time-series-compression)\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for exploring fractal time series compression!** üåÄ\n",
    "\n",
    "If you found this useful, please ‚≠ê star the repository and share with others interested in fractal mathematics and signal processing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_summary"
   },
   "outputs": [],
   "source": [
    "# Final summary and save option\n",
    "print(\"üéâ FRACTAL COMPRESSION DEMO COMPLETE!\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "if results:\n",
    "    print(\"\\nüìä SESSION SUMMARY:\")\n",
    "    print(f\"‚Ä¢ Tested {len(results)} compression methods\")\n",
    "    print(f\"‚Ä¢ Analyzed {len(test_signals)} different signal types\")\n",
    "    print(f\"‚Ä¢ Generated comprehensive visualizations\")\n",
    "    print(f\"‚Ä¢ Explored parameter sensitivity\")\n",
    "    \n",
    "    # Best overall result\n",
    "    if len(results) > 1:\n",
    "        best_overall = max(results, key=lambda x: x['metrics']['pearson_correlation'] * x['metrics']['compression_ratio'])\n",
    "        print(f\"\\nüèÜ BEST OVERALL PERFORMANCE:\")\n",
    "        print(f\"   Method: {best_overall['name']}\")\n",
    "        print(f\"   Compression: {best_overall['metrics']['compression_ratio']:.2f}x\")\n",
    "        print(f\"   Quality: {best_overall['metrics']['pearson_correlation']:.4f}\")\n",
    "        print(f\"   Combined Score: {best_overall['metrics']['pearson_correlation'] * best_overall['metrics']['compression_ratio']:.2f}\")\n",
    "\n",
    "print(\"\\nüîó USEFUL LINKS:\")\n",
    "print(\"‚Ä¢ Repository: https://github.com/ParkerWilliams/fractal-time-series-compression\")\n",
    "print(\"‚Ä¢ Colab Notebook: [This notebook]\")\n",
    "print(\"‚Ä¢ Issues/Questions: https://github.com/ParkerWilliams/fractal-time-series-compression/issues\")\n",
    "\n",
    "print(\"\\nüí° NEXT STEPS:\")\n",
    "print(\"1. Try with your own time series data\")\n",
    "print(\"2. Experiment with different parameters\")\n",
    "print(\"3. Compare with traditional compression methods\")\n",
    "print(\"4. Explore the fractal properties of your signals\")\n",
    "print(\"5. Share your results with the community!\")\n",
    "\n",
    "print(\"\\nüåü If you found this helpful, please star the repository! ‚≠ê\")\n",
    "print(\"\\nüéØ Happy fractal compressing! üåÄ\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}